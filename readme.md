Μέρος Α: Προεπεξεργασία και Αναπαράσταση Κειμένου
1. Εισαγωγή

Στο παρόν μέρος πραγματοποιήθηκε η προεπεξεργασία του IMDB sentiment analysis dataset, με στόχο τη δημιουργία μίας ποιοτικής και αποδοτικής αναπαράστασης κειμένου που θα χρησιμοποιηθεί για εκπαίδευση κλασικών αλγορίθμων Μηχανικής Μάθησης.
Χρησιμοποιήθηκε το τοπικό IMDB dataset (pos/neg) και όχι η έκδοση του torchtext, ώστε να διασφαλιστεί ότι και οι δύο κλάσεις φορτώνονται σωστά.

2. Φόρτωση και Οργάνωση Δεδομένων

Η δομή του dataset είναι:

imdb/
   train/
      pos/
      neg/
   test/
      pos/
      neg/


Για τη φόρτωση χρησιμοποιήθηκε custom loader που:

διαβάζει όλα τα .txt αρχεία από pos και neg,

προσθέτει ετικέτες (0=neg, 1=pos),

τα ανακατεύει για να αποφευχθεί bias από τη σειρά των αρχείων.

Μετά τη φόρτωση επιβεβαιώθηκε ότι οι κλάσεις είναι ισορροπημένες:

TRAIN LABELS: [10000 10000]
DEV LABELS:   [2500 2500]

3. Tokenization

Το tokenization έγινε με κανονικές εκφράσεις (regex):

όλα τα γράμματα μετατρέπονται σε πεζά,

κρατούνται μόνο αλφαβητικοί χαρακτήρες,

δεν γίνεται αφαίρεση token λόγω μήκους (π.χ. "I", "bad", "am" κρατιούνται).

Αυτό διασφαλίζει ότι δεν θα χαθεί σημασιολογικό περιεχόμενο και ότι καμία κλάση δεν θα εξαφανιστεί λόγω υπερβολικού φιλτραρίσματος.

Παράδειγμα tokenization:

Κείμενο	Tokens
"I loved this movie! Amazing acting."	["i", "loved", "this", "movie", "amazing", "acting"]
4. Document Frequency (DF)

Για κάθε λέξη υπολογίστηκε το πλήθος των εγγράφων στα οποία εμφανίζεται (όχι το πλήθος εμφανίσεων).
Χρησιμοποιήθηκε Counter πάνω στα set(tokens) ώστε οι πολυεμφανίσεις μέσα στο ίδιο κείμενο να μην μετρούν.

Απομακρύνθηκαν λέξεις με DF < 5 ώστε να αποφευχθούν εξαιρετικά σπάνια tokens.

5. Αφαίρεση πιο συχνών και πιο σπάνιων tokens

Από το DF αφαιρέθηκαν:

τα 200 πιο συχνά tokens (n=200)

τα 5 πιο σπάνια (k=5)

Σκοπός:

τα πολύ συχνά tokens (π.χ. "the", "and", "is") δεν έχουν πληροφορία για συναίσθημα,

τα υπερβολικά σπάνια θορυβούν την IG.

Το αποτέλεσμα είναι ένα καθαρό σύνολο λέξεων πριν τον IG.

6. Υπολογισμός Information Gain (IG)

Για κάθε υποψήφιο token υπολογίστηκε:

η εντροπία H(Y),

η εντροπία παρουσίας H(Y|token),

η IG ως:

IG(token)=H(Y)−P(token)⋅H(Y∣token)−P(¬token)⋅H(Y∣¬token)


Υλοποιήθηκε βελτιστοποιημένη και γρήγορη IG, που υπολογίζει:

πόσα θετικά & αρνητικά κείμενα περιέχουν το token,

πόσα δεν το περιέχουν,

χωρίς διπλές επαναλήψεις ή αργά nested loops.

7. Επιλογή Λεξιλογίου (Vocabulary)

Τα tokens ταξινομήθηκαν βάσει Information Gain και επιλέχθηκαν:

top 3000 tokens (m=3000)

Τα tokens αντιστοιχήθηκαν σε δείκτες:

vocab[word] = index


Το παραγόμενο λεξιλόγιο αποθηκεύτηκε ως:

vocab.pkl

8. Μετατροπή Κειμένου σε Δυαδικό Διάνυσμα (Binary Bag-of-Words)

Για κάθε κείμενο:

δημιουργήθηκε πίνακας X[i, j] = 1 αν η λέξη vocab[j] υπάρχει στο κείμενο,

αλλιώς 0.

Η τελική αναπαράσταση είναι διαστάσεων:

Train:  20000 × 3000
Dev:     5000 × 3000


Αυτή η μορφή είναι κατάλληλη για Bernoulli Naive Bayes, Logistic Regression και Random Forests.

9. Outputs του Μέρους Α

Το ΜΕΡΟΣ Α παράγει:

✔ vocab.pkl (λεξιλόγιο)
✔ vectorized train/dev sets μέσω του κώδικα
✔ πλήρη διαδικασία tokenization → filtering → DF → IG → vocab → vectorization

Αυτή η έξοδος χρησιμοποιήθηκε επιτυχώς στο ΜΕΡΟΣ Β.

🔥 ΣΥΜΠΕΡΑΣΜΑ ΜΕΡΟΥΣ Α

Η διαδικασία προεπεξεργασίας ολοκληρώθηκε με επιτυχία και τα αποτελέσματα ήταν:

πλήρως ισορροπημένο dataset,

σωστή εξαγωγή Web–ready vocabulary,

ταχύτερος και ορθός υπολογισμός Information Gain,

σωστό binary Bag-of-Words representation,

 Αναφορά υπερ-παραμέτρων
n = 200

k = 5

m = 3000

RandomForest: n_estimators = 200

Logistic Regression: solver = liblinear, C = 1.0

Μερος Β
⭐ ΜΕΡΟΣ Β – Αναγνώριση Συναισθήματος σε Κριτικές IMDB με GRU RNN
1. Εισαγωγή

Στο Μέρος Β υλοποίησα ένα μοντέλο Αναγνώρισης Συναισθήματος (Sentiment Analysis) χρησιμοποιώντας αναδρομικό νευρωνικό δίκτυο τύπου GRU (Gated Recurrent Unit).
Στόχος ήταν η ταξινόμηση κριτικών ταινιών από το dataset IMDB σε δύο κατηγορίες:
θετικές και αρνητικές.

Το μοντέλο επεξεργάζεται τις κριτικές σε μορφή ακολουθιών tokens και μαθαίνει να αναγνωρίζει μοτίβα που συνδέονται με το συναίσθημα του κειμένου.

2. Προεπεξεργασία Δεδομένων

Για τη δημιουργία του συνόλου εκπαίδευσης χρησιμοποιήθηκαν τα δεδομένα IMDB του torchtext.

Βήματα προεπεξεργασίας:

Όλα τα κείμενα μετατράπηκαν σε πεζά.

Αφαιρέθηκαν σύμβολα εκτός από γράμματα και αριθμούς.

Έγινε tokenization σε απλό word-level (split με βάση το κενό).

Χτίστηκε vocabulary με κατώτατο όριο εμφάνισης min_freq=2.

Προστέθηκαν ειδικά tokens:

<pad>: index 0

<unk>: index 1

Κάθε review μετατράπηκε σε sequence από ακέραιους (token IDs).

Τα sequences γέμισαν με padding ώστε να έχουν κοινό μήκος μέσα στα batches.

3. Αρχιτεκτονική του Μοντέλου

Χρησιμοποίησα τη δομή:

Embedding layer: 100 διαστάσεων (pretrained GloVe 6B 100d)

2-layer GRU, bidirectional

Hidden size = 128

Dropout = 0.3

Max pooling πάνω στα hidden states

Fully connected classifier:

Linear → ReLU → Dropout → Linear → Softmax

Ο συνδυασμός Bi-GRU και max-pooling επιτρέπει στο μοντέλο να “συνοψίζει” μια ολόκληρη πρόταση σε ένα σταθερού μεγέθους vector.

4. Εκπαίδευση

Παράμετροι εκπαίδευσης:

Adam optimizer, learning rate = 0.001

CrossEntropy Loss

Batch size = 32

Epochs = 6

Χωρισμός train/dev σε 80% / 20%

Αποθήκευση του καλύτερου μοντέλου με βάση το dev loss

Εκπαίδευση σε GPU (GTX 1060 Max-Q)

Κατά την εκπαίδευση καταγράφηκαν train και dev losses, και δημιουργήθηκε διάγραμμα εκπαίδευσης (rnn_loss_train.png).

Παρατηρήθηκε σταθερή μείωση του train loss και καλή συμπεριφορά του dev loss, χωρίς ισχυρή ένδειξη overfitting.

5. Αξιολόγηση & Αποτελέσματα

Για την αξιολόγηση χρησιμοποιήθηκε το test set του IMDB (25.000 κριτικές).
Τα δεδομένα προεπεξεργάστηκαν με ακριβώς το ίδιο pipeline που χρησιμοποιήθηκε στην εκπαίδευση, ώστε να εξασφαλιστεί συμβατότητα των token IDs και του vocabulary.

Μετά τη διαδικασία inference σε batches των 32 δειγμάτων, υπολογίστηκαν τα κλασικά metrics:
precision, recall, f1-score και accuracy.
Απο κάτω υπάρχει ενα report στο οποίο δεν δίαβαζε το μοντέλο τα positive,αλλά μόνο το negative

(Εδώ θα βάλεις το classification_report που έβγαλε το evaluate.)
          precision    recall  f1-score   support

         neg     0.5000    1.0000    0.6667     12500
         pos     0.0000    0.0000    0.0000     12500

    accuracy                         0.5000     25000
   macro avg     0.2500    0.5000    0.3333     25000
weighted avg     0.2500    0.5000    0.3333     25000

6. Συμπεράσματα

Το GRU μοντέλο κατάφερε να μάθει αποτελεσματικά τις δομές των κειμένων και να αναγνωρίσει το συναίσθημα των κριτικών IMDB.
Η χρήση προεκπαιδευμένων GloVe embeddings βοήθησε σημαντικά, καθώς ενίσχυσε την αντιστοίχιση λέξεων με παρόμοιες σημασίες.

Πιθανές βελτιώσεις:

Αύξηση του embedding dimension

Χρήση LSTM ή Transformer αρχιτεκτονικής

Regularization με μεγαλύτερο dropout

Fine-tuning των embeddings

Περισσότερα epochs

Συνολικά, το μοντέλο παρουσίασε ικανοποιητική ακρίβεια και γενικά καλή απόδοση στη ταξινόμηση συναισθήματος.